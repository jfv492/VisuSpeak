{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbb78ca3",
   "metadata": {},
   "source": [
    "### gen_pose.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f80dcfb2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Failed to import `inference_detector` and `init_detector` form `mmdet.apis`. These apis are required in this script! ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 36\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmmdet\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmmdet\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapis\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m inference_detector, init_detector\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m):\n",
      "File \u001b[0;32m~/miniconda/envs/tf_m1/lib/python3.8/site-packages/mmdet/apis/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) OpenMMLab. All rights reserved.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdet_inferencer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DetInferencer\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (async_inference_detector, inference_detector,\n\u001b[1;32m      4\u001b[0m                         inference_mot, init_detector, init_track_model)\n",
      "File \u001b[0;32m~/miniconda/envs/tf_m1/lib/python3.8/site-packages/mmdet/apis/det_inferencer.py:11\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmmcv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LoadImageFromFile\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmmengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Compose\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mmcv.transforms'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmmdet\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapis\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m inference_detector, init_detector\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m):\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFailed to import `inference_detector` and \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     39\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`init_detector` form `mmdet.apis`. These apis are \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     40\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrequired in this script! \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmmpose\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Failed to import `inference_detector` and `init_detector` form `mmdet.apis`. These apis are required in this script! "
     ]
    }
   ],
   "source": [
    "# Copyright (c) OpenMMLab. All rights reserved.\n",
    "# https://github.com/kennymckormick/pyskl/blob/main/tools/data/custom_2d_skeleton.py\n",
    "import argparse\n",
    "from gc import garbage\n",
    "import os\n",
    "from unittest.mock import NonCallableMagicMock\n",
    "import os.path as osp\n",
    "from torch.utils.data import DataLoader, sampler\n",
    "import torch\n",
    "import cv2, time\n",
    "from functools import partial\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import torch.distributed as dist\n",
    "from tqdm import tqdm\n",
    "from utils.misc import (\n",
    "    get_logger,\n",
    "    load_config,\n",
    "    log_cfg,\n",
    "    load_checkpoint,\n",
    "    make_model_dir,\n",
    "    make_logger, make_writer,\n",
    "    set_seed,\n",
    "    symlink_update,\n",
    "    is_main_process, init_DDP, move_to_device,\n",
    "    neq_load_customized,\n",
    "    synchronize,\n",
    "    merge_pkls\n",
    ")\n",
    "import pickle\n",
    "from dataset.Dataloader import build_dataloader\n",
    "\n",
    "try:\n",
    "    import mmdet\n",
    "    from mmdet.apis import inference_detector, init_detector\n",
    "except (ImportError, ModuleNotFoundError):\n",
    "    raise ImportError('Failed to import `inference_detector` and '\n",
    "                      '`init_detector` form `mmdet.apis`. These apis are '\n",
    "                      'required in this script! ')\n",
    "\n",
    "try:\n",
    "    import mmpose\n",
    "    from mmpose.apis import inference_topdown, init_model, visualize\n",
    "except (ImportError, ModuleNotFoundError):\n",
    "    raise ImportError('Failed to import `inference_top_down_pose_model` and '\n",
    "                      '`init_pose_model` form `mmpose.apis`. These apis are '\n",
    "                      'required in this script! ')\n",
    "\n",
    "default_mmdet_root = osp.dirname(mmdet.__path__[0])\n",
    "default_mmpose_root = osp.dirname(mmpose.__path__[0])\n",
    "default_det_config = (\n",
    "    f'{default_mmdet_root}/mmdet/configs/faster_rcnn/'\n",
    "    'faster_rcnn_r50_caffe_fpn_mstrain_1x_coco-person.py')\n",
    "default_det_ckpt = (\n",
    "    'https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco-person/'\n",
    "    'faster_rcnn_r50_fpn_1x_coco-person_20201216_175929-d022e227.pth')\n",
    "default_pose_config = (\n",
    "    f'{default_mmpose_root}/configs/wholebody/2d_kpt_sview_rgb_img/topdown_heatmap/'\n",
    "    'coco-wholebody/hrnet_w48_coco_wholebody_384x288_dark_plus.py')\n",
    "default_pose_ckpt = (\n",
    "    'https://download.openmmlab.com/mmpose/top_down/hrnet/'\n",
    "    'hrnet_w48_coco_wholebody_384x288_dark-f5726563_20200918.pth')\n",
    "\n",
    "\n",
    "def detection_inference(model, frames):\n",
    "    results = []\n",
    "    for frame in frames:\n",
    "        result = inference_detector(model, frame[0])\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "\n",
    "def pose_inference(model, frames, det_results):\n",
    "    garbage_frame = 0\n",
    "    if det_results is not None:\n",
    "        assert len(frames) == len(det_results)\n",
    "        total_frames = len(frames)\n",
    "        kp = np.zeros((total_frames, 133, 3), dtype=np.float32)\n",
    "        # bb = np.zeros((total_frames, 5), dtype=np.float32)\n",
    "\n",
    "        for i, (f, d) in enumerate(zip(frames, det_results)):\n",
    "            # Align input format\n",
    "            d = [dict(bbox=x) for x in list(d)]\n",
    "            pose = inference_top_down_pose_model(model, f, d, format='xyxy')[0]\n",
    "            if pose == []:\n",
    "                # not detect person\n",
    "                garbage_frame += 1\n",
    "                continue\n",
    "            pose = sorted(pose, key=lambda x:x['bbox'][-1])\n",
    "            keypoints, bbox = pose[-1]['keypoints'], pose[-1]['bbox']\n",
    "            kp[i] = keypoints\n",
    "            # bb[i] = bbox\n",
    "\n",
    "    else:\n",
    "        print(frames.shape)\n",
    "        d = [{'bbox': np.array([0, 0, frames.shape[2]-1, frames.shape[1]-1])}]\n",
    "        pose = inference_top_down_pose_model(model, frames[0], None, format='xyxy')[0]\n",
    "\n",
    "    return kp, garbage_frame\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='Generate 2D pose annotations for a custom video dataset')\n",
    "    # * Both mmdet and mmpose should be installed from source\n",
    "    parser.add_argument('--mmdet-root', type=str, default=default_mmdet_root)\n",
    "    parser.add_argument('--mmpose-root', type=str, default=default_mmpose_root)\n",
    "    parser.add_argument('--det-config', type=str, default=default_det_config)\n",
    "    parser.add_argument('--det-ckpt', type=str, default=default_det_ckpt)\n",
    "    parser.add_argument('--pose-config', type=str, default=default_pose_config)\n",
    "    parser.add_argument('--pose-ckpt', type=str, default=default_pose_ckpt)\n",
    "    # * Only det boxes with score larger than det_score_thr will be kept\n",
    "    parser.add_argument('--det-score-thr', type=float, default=0.5)\n",
    "    # * Only det boxes with large enough sizes will be kept,\n",
    "    parser.add_argument('--det-area-thr', type=float, default=1600)\n",
    "    # * Accepted formats for each line in video_list are:\n",
    "    # * 1. \"xxx.mp4\" ('label' is missing, the dataset can be used for inference, but not training)\n",
    "    # * 2. \"xxx.mp4 label\" ('label' is an integer (category index),\n",
    "    # * the result can be used for both training & testing)\n",
    "    # * All lines should take the same format.\n",
    "    parser.add_argument('--video-list', type=str, help='the list of source videos')\n",
    "    # * out should ends with '.pkl'\n",
    "    parser.add_argument('--out', type=str, help='output pickle name')\n",
    "    parser.add_argument('--tmpdir', type=str, default='./tmp')\n",
    "    parser.add_argument('--local_rank', type=int, default=0)\n",
    "\n",
    "    parser.add_argument('--split', type=str, default='train', choices=['train', 'dev', 'test'])\n",
    "    parser.add_argument('--start_end', nargs='+', type=int, default=None, help='for multi-node')\n",
    "    parser.add_argument('--from_ckpt', type=int, default=0 ,choices=[0,1])\n",
    "    parser.add_argument('--img_per_iter', type=int, default=100)\n",
    "    parser.add_argument('--gpu', type=int, default=1)\n",
    "    parser.add_argument(\"--config\", default=\"configs/det.yaml\", type=str, help=\"Training configuration file (yaml).\")\n",
    "    args = parser.parse_args()\n",
    "    if 'LOCAL_RANK' not in os.environ:\n",
    "        os.environ['LOCAL_RANK'] = str(args.local_rank)\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "def main():\n",
    "    set_seed(8)\n",
    "    args = parse_args()\n",
    "    cfg = load_config(args.config)\n",
    "    cfg['local_rank'], cfg['world_size'], cfg['device'] = init_DDP()\n",
    "    model_dir = cfg['training']['model_dir']\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    global logger\n",
    "    logger = make_logger(model_dir=model_dir, log_file='gen_pose_{}_{}.log'.format(args.split, cfg['local_rank']))\n",
    "\n",
    "    if cfg['data']['dataset_name'] == 'wlasl':\n",
    "        path = osp.join('../../data/wlasl_2000', 'keypoints_hrnet_dark_coco_wholebody')\n",
    "        h, w = 256, 256\n",
    "    elif cfg['data']['dataset_name'] == 'MSASL_1000':\n",
    "        path = osp.join('../../data/msasl', 'keypoints_hrnet_dark_coco_wholebody')\n",
    "        h, w = 256, 256\n",
    "    elif cfg['data']['dataset_name'] == 'NMFs-CSL':\n",
    "        path = osp.join('../../data/NMFs-CSL', 'keypoints_hrnet_dark_coco_wholebody')\n",
    "        h, w = 512, 512\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    dataloader, sampler = build_dataloader(cfg, args.split, is_train=False, val_distributed=True)\n",
    "\n",
    "    # get existing pkls\n",
    "    if args.from_ckpt:\n",
    "        ckpts = {}\n",
    "        for fname in os.listdir(path):\n",
    "            if 'pkl' in fname and args.split in fname:\n",
    "                with open(osp.join(path, fname), 'rb') as f:\n",
    "                    data = pickle.load(f)\n",
    "                    ckpts.update(data)\n",
    "        ckpt_ids = list(ckpts.keys())\n",
    "        print('num of ckpts: ', len(ckpt_ids))\n",
    "        if cfg['local_rank'] == 0:\n",
    "            merge_pkls(path, args.split, True)\n",
    "        ckpts = {}\n",
    "\n",
    "    det_model = init_detector(args.det_config, args.det_ckpt, 'cuda')\n",
    "    assert det_model.CLASSES[0] == 'person', 'A detector trained on COCO is required'\n",
    "    pose_model = init_pose_model(args.pose_config, args.pose_ckpt, 'cuda')\n",
    "    \n",
    "    outputs = {}\n",
    "    save_inte = 500\n",
    "    for k, batch_data in tqdm(enumerate(dataloader), desc='[Generating keypoints of {:s} of {:s}, {:d} per gpu]'.format(args.split, cfg['data']['dataset_name'], len(dataloader))):\n",
    "        frames = batch_data['sgn_videos'][0][0].numpy().transpose(0,2,3,1)*255  #[T,H,W,3]\n",
    "        frames = np.uint8(frames)\n",
    "        frames = np.split(frames, frames.shape[0], axis=0)\n",
    "        video_id = batch_data['names'][0]\n",
    "\n",
    "        if args.from_ckpt and video_id in ckpt_ids:\n",
    "            if (k+1)%save_inte == 0:\n",
    "                fname = '{:s}_{:d}_{:d}.pkl'.format(args.split, cfg['local_rank'], k)\n",
    "                print('save to '+fname)\n",
    "                with open(os.path.join(path, fname), 'wb') as f:\n",
    "                    pickle.dump(outputs, f)\n",
    "                outputs = {}\n",
    "            continue\n",
    "        \n",
    "        det_results = detection_inference(det_model, frames)\n",
    "        # * Get detection results for human\n",
    "        det_results = [x[0] for x in det_results]\n",
    "        for i, res in enumerate(det_results):\n",
    "            # * filter boxes with small scores\n",
    "            res = res[res[:, 4] >= args.det_score_thr]\n",
    "            # * filter boxes with small areas\n",
    "            box_areas = (res[:, 3] - res[:, 1]) * (res[:, 2] - res[:, 0])\n",
    "            assert np.all(box_areas >= 0)\n",
    "            res = res[box_areas >= args.det_area_thr]\n",
    "            det_results[i] = res\n",
    "\n",
    "        pose_results, garbage_frame = pose_inference(pose_model, frames, det_results)\n",
    "\n",
    "        # if k%save_inte==0:\n",
    "        #     # visulize video\n",
    "        #     fps=15\n",
    "        #     fourcc=cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "        #     video_writer = cv2.VideoWriter('vis_res/'+video_id.split('/')[-1]+'_hrnet.mp4', cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w,h))\n",
    "        #     for idx in range(len(frames)):\n",
    "        #         img = frames[idx][0, ..., ::-1].astype(np.uint8)\n",
    "        #         # print(img)\n",
    "        #         cv2.imwrite('temp.png', img)\n",
    "        #         img = cv2.imread('temp.png')\n",
    "        #         # bb_x1, bb_y1, bb_x2, bb_y2 = bb_results[idx, :-1]\n",
    "        #         # cv2.line(f, (int(bb_x1), int(bb_y1)), (int(bb_x1), int(bb_y2)), (0,255,0))\n",
    "        #         # cv2.line(f, (int(bb_x1), int(bb_y1)), (int(bb_x2), int(bb_y1)), (0,255,0))\n",
    "        #         # cv2.line(f, (int(bb_x2), int(bb_y2)), (int(bb_x2), int(bb_y1)), (0,255,0))\n",
    "        #         # cv2.line(f, (int(bb_x2), int(bb_y2)), (int(bb_x1), int(bb_y2)), (0,255,0))\n",
    "        #         for j in range(133):\n",
    "        #             x,y = pose_results[idx, j, :-1]\n",
    "        #             x,y = int(x), int(y)\n",
    "        #             cv2.circle(img, (x,y), 1, (0,0,255))\n",
    "        #         cv2.imwrite('temp.png', img)\n",
    "        #         img = cv2.imread('temp.png')\n",
    "        #         video_writer.write(img)\n",
    "\n",
    "        #         # vis_pose_result(pose_model,\n",
    "        #         #                 img,\n",
    "        #         #                 result=[{'keypoints': pose_results[idx]}],\n",
    "        #         #                 radius=1,\n",
    "        #         #                 thickness=1,\n",
    "        #         #                 kpt_score_thr=0.3,\n",
    "        #         #                 bbox_color='green',\n",
    "        #         #                 dataset='TopDownCocoWholeBodyDataset',\n",
    "        #         #                 dataset_info=None,\n",
    "        #         #                 show=False,\n",
    "        #         #                 out_file='temp.png')\n",
    "        #         # f = cv2.imread('temp.png')\n",
    "        #         # video_writer.write(f)\n",
    "        #     video_writer.release()\n",
    "        \n",
    "        assert pose_results.shape == (batch_data['vlens'][0], 133, 3)\n",
    "        # np.savez_compressed(fname+'.npz', keypoints=pose_results.astype(np.float16))\n",
    "        outputs[video_id] = pose_results.astype(np.float32)\n",
    "        if (k+1)%save_inte == 0:\n",
    "            if args.start_end is None:\n",
    "                fname = '{:s}_rank{:d}_{:d}.pkl'.format(args.split, cfg['local_rank'], k)\n",
    "            else:\n",
    "                fname = '{:s}_rank{:d}_start{:d}_end{:d}_{:d}.pkl'.format(args.split, cfg['local_rank'], args.start_end[0], args.start_end[1], k)\n",
    "            print('save to '+fname)\n",
    "            with open(os.path.join(path, fname), 'wb') as f:\n",
    "                pickle.dump(outputs, f)\n",
    "            outputs = {}\n",
    "    \n",
    "    if outputs != {}:\n",
    "        if args.start_end is None:\n",
    "            fname = '{:s}_rank{:d}_{:d}.pkl'.format(args.split, cfg['local_rank'], k)\n",
    "        else:\n",
    "            fname = '{:s}_rank{:d}_start{:d}_end{:d}_{:d}.pkl'.format(args.split, cfg['local_rank'], args.start_end[0], args.start_end[1], k)\n",
    "        print('save to '+fname)\n",
    "        with open(os.path.join(path, fname), 'wb') as f:\n",
    "            pickle.dump(outputs, f)\n",
    "        outputs = {}\n",
    "\n",
    "    merge_pkls(path, args.split)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d215ff7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
